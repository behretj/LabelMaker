{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from segmentation_tools.visualisation import draw_sem_seg, VisImage\n",
    "from segmentation_tools.label_data import get_ade150, get_nyu40, get_scannet_all, get_wordnet, get_replica\n",
    "from segmentation_tools.label_mappings import set_ids_according_to_names, \\\n",
    "        match_scannet_ade150, \\\n",
    "        match_scannet_nyu40, \\\n",
    "        match_ade150_nyu40, \\\n",
    "        match_scannet_wordnet199, \\\n",
    "        LabelMatcher, \\\n",
    "        set_colors\n",
    "from pathlib import Path\n",
    "from scripts import segmentation_eval\n",
    "from scripts import pointcloud_eval\n",
    "from scripts import segmentation_consensus\n",
    "import skimage\n",
    "\n",
    "key = 50\n",
    "scene_dir = Path('/home/weders/scratch/scratch/scannetter/room_0_1')\n",
    "img = cv2.imread(f'{scene_dir}/rgb/rgb_{key}.png')[..., ::-1]\n",
    "label = cv2.imread(f'{scene_dir}/semantic_class/semantic_class_{key}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "# our_label = cv2.imread(f'{scene_dir}/label_agile3d/{key}.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "consensus = cv2.imread(f'{scene_dir}/pred_wn_consensus/{key}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "# sdfstudio = cv2.imread(f'{scene_dir}/pred_sdfstudio_2023-07-19_164624/{(key // 2):05d}.png',\n",
    "#                    cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "\n",
    "classid2wn = {x['id']: x['name'] for x in get_wordnet(label_key='wn199-merged-v2')}\n",
    "scannet_id_to_name = {x['id'] : x['name'] for x in get_scannet_all()}\n",
    "scannet_id_to_color = {x['id'] : x['color'] for x in get_scannet_all()}\n",
    "\n",
    "print(classid2wn)\n",
    "\n",
    "keys = sorted(\n",
    "            int(x.name.split('.')[0].split('_')[-1])\n",
    "            for x in (scene_dir / 'rgb').iterdir())\n",
    "label_template = 'semantic_class/semantic_class_{k}.png'\n",
    "label_space = 'id'\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(img)\n",
    "plt.gca().axis('off')\n",
    "plt.show()\n",
    "_, plots = plt.subplots(1, 4, figsize=(30, 10))\n",
    "vis = VisImage(img)\n",
    "# draw_sem_seg(our_label, vis, \n",
    "#             classes=[x['name'] for x in sorted(get_wordnet(), key=lambda x: x['id'])],\n",
    "#             colors=[x['color'] for x in sorted(get_wordnet(), key=lambda x: x['id'])])\n",
    "# plots[0].imshow(vis.get_image())\n",
    "plots[0].axis('off')\n",
    "plots[0].set_title('Ground Truth')\n",
    "vis = VisImage(img)\n",
    "draw_sem_seg(label, vis, \n",
    "             classes=[scannet_id_to_name[i] if i in scannet_id_to_name else 'unknown' for i in range(2000)],\n",
    "             colors=[scannet_id_to_color[i] if i in scannet_id_to_name else [0, 0, 0] for i in range(2000)],)\n",
    "plots[1].imshow(vis.get_image())\n",
    "plots[1].axis('off')\n",
    "plots[1].set_title('ScanNet')\n",
    "# vis = VisImage(img)\n",
    "# draw_sem_seg(sdfstudio, vis, \n",
    "#             classes=[x['name'] for x in sorted(get_wordnet(), key=lambda x: x['id'])],\n",
    "#             colors=[x['color'] for x in sorted(get_wordnet(), key=lambda x: x['id'])])\n",
    "#plots[2].imshow(vis.get_image())\n",
    "# plots[2].axis('off')\n",
    "plots[2].set_title('LabelMaker3D')\n",
    "vis = VisImage(img)\n",
    "draw_sem_seg(consensus, vis, \n",
    "             classes=[x['name'] for x in sorted(get_wordnet(), key=lambda x: x['id'])],\n",
    "             colors=[x['color'] for x in sorted(get_wordnet(), key=lambda x: x['id'])])\n",
    "plots[3].imshow(vis.get_image())\n",
    "plots[3].axis('off')\n",
    "plots[3].set_title('Consensus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# iterate over all frames for scene\n",
    "\n",
    "scene = 'scene0000_00'\n",
    "scene_dir = Path(f'/home/weders/scratch/scratch/scannetter/{scene}')\n",
    "sdfstudio_pred = 'pred_sdfstudio_2023-07-30_112430'\n",
    "\n",
    "keys = sorted([int(k.split('/')[-1].replace('.jpg', '')) for k in os.listdir((scene_dir / 'color'))])\n",
    "\n",
    "for idx, key in enumerate(keys):\n",
    "    \n",
    "    if idx % 20 != 0:\n",
    "        continue\n",
    "        \n",
    "    img = cv2.imread(f'{scene_dir}/color/{key}.jpg')[..., ::-1]\n",
    "    label = cv2.imread(f'{scene_dir}/label-filt/{key}.png',\n",
    "                       cv2.IMREAD_UNCHANGED)\n",
    "    our_label = cv2.imread(f'{scene_dir}/label_agile3d/{key}.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    consensus = cv2.imread(f'{scene_dir}/pred_consensus_5_scannet/{key}.png',\n",
    "                       cv2.IMREAD_UNCHANGED)\n",
    "    sdfstudio = cv2.imread(f'{scene_dir}/{sdfstudio_pred}/{(key // 2):05d}.png',\n",
    "                       cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    classid2wn = {x['id']: x['name'] for x in get_wordnet()}\n",
    "    scannet_id_to_name = {x['id'] : x['name'] for x in get_scannet_all()}\n",
    "    scannet_id_to_color = {x['id'] : x['color'] for x in get_scannet_all()}\n",
    "\n",
    "    classes = [x['name'] for x in sorted(get_wordnet(label_key='wn199-merged-v2'), key=lambda x: x['id'])]\n",
    "    \n",
    "    keys = sorted(\n",
    "                int(x.name.split('.')[0])\n",
    "                for x in (scene_dir / 'color').iterdir())\n",
    "    label_template = 'label-filt/{k}.png'\n",
    "    label_space = 'id'\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     plt.imshow(img)\n",
    "#     plt.gca().axis('off')\n",
    "#     plt.show()\n",
    "    _, plots = plt.subplots(1, 5, figsize=(40, 10))\n",
    "    \n",
    "    plots[0].imshow(img)\n",
    "    plots[0].axis('off')\n",
    "    plots[0].set_title('Image')\n",
    "    \n",
    "    vis = VisImage(img)\n",
    "    draw_sem_seg(our_label, vis, \n",
    "                 classes={x['id']: x['name'] for x in sorted(get_wordnet(label_key='wn199-merged-v2'), key=lambda x: x['id'])},\n",
    "                 colors=[x['color'] for x in sorted(get_wordnet(label_key='wn199-merged-v2'), key=lambda x: x['id'])])\n",
    "    plots[1].imshow(vis.get_image())\n",
    "    plots[1].axis('off')\n",
    "    plots[1].set_title('Ground Truth')\n",
    "    vis = VisImage(img)\n",
    "    draw_sem_seg(label, vis, \n",
    "                 classes=[scannet_id_to_name[i] if i in scannet_id_to_name else 'unknown' for i in range(2000)],\n",
    "                 colors=[scannet_id_to_color[i] if i in scannet_id_to_name else [0, 0, 0] for i in range(2000)],)\n",
    "    plots[2].imshow(vis.get_image())\n",
    "    plots[2].axis('off')\n",
    "    plots[2].set_title('ScanNet')\n",
    "    vis = VisImage(img)\n",
    "    draw_sem_seg(sdfstudio, vis, \n",
    "                 classes=[x['name'] for x in sorted(get_wordnet(label_key='wn199-merged-v2'), key=lambda x: x['id'])],\n",
    "                 colors=[x['color'] for x in sorted(get_wordnet(label_key='wn199-merged-v2'), key=lambda x: x['id'])])\n",
    "    plots[3].imshow(vis.get_image())\n",
    "    plots[3].axis('off')\n",
    "    plots[3].set_title('LabelMaker3D')\n",
    "    vis = VisImage(img)\n",
    "    draw_sem_seg(consensus, vis, \n",
    "                 classes=[x['name'] for x in sorted(get_wordnet(label_key='wn199-merged-v2'), key=lambda x: x['id'])],\n",
    "                 colors=[x['color'] for x in sorted(get_wordnet(label_key='wn199-merged-v2'), key=lambda x: x['id'])])\n",
    "    plots[4].imshow(vis.get_image())\n",
    "    plots[4].axis('off')\n",
    "    plots[4].set_title('Consensus')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_colors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis = VisImage(img)\n",
    "draw_sem_seg(our_label, vis, classes=[x['name'] for x in sorted(get_wordnet(), key=lambda x: x['id'])])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis = VisImage(cv2.resize(img, (1296, 968)))\n",
    "scannet_id_to_name = {x['id'] : x['name'] for x in get_scannet_all()}\n",
    "draw_sem_seg(label, vis, classes=[scannet_id_to_name[i] if i in scannet_id_to_name else 'unknown' for i in range(2000)])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matcher = LabelMatcher('id', 'wn199', verbose=False)\n",
    "vis = VisImage(img, scale=1)\n",
    "draw_sem_seg(matcher.match(label, our_label), vis, classes=['mismatch', 'match', 'unknown'])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inst_sam = cv2.imread(f'{scene_dir}/pred_sam/{key}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "vis = VisImage(img, scale=1)\n",
    "draw_sem_seg(inst_sam, vis, classes=[str(i) for i in range(200)])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ovseg_wn = cv2.imread(f'{scene_dir}/pred_ovseg_wn_nodef/{key}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "vis = VisImage(img, scale=1)\n",
    "draw_sem_seg(ovseg_wn, vis, \n",
    "             classes=[x['name'] for x in sorted(get_wordnet(), key=lambda x: x['id'])],\n",
    "             colors=[x['color'] for x in sorted(get_wordnet(), key=lambda x: x['id'])])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intern = cv2.imread(f'{scene_dir}/pred_internimage/{key}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "vis = VisImage(img, scale=1)\n",
    "draw_sem_seg(intern, vis, classes=[x['name'] for x in sorted(get_ade150(), key=lambda x: x['id'])])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmx = cv2.imread(f'{scene_dir}/pred_cmx/{key}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "vis = VisImage(cv2.resize(img, (640, 480)))\n",
    "draw_sem_seg(cmx, vis, classes=['unknown'] + [x['name'] for x in sorted(get_nyu40(), key=lambda x: int(x['id']))])\n",
    "#draw_sem_seg(cmx, vis, classes=[str(x) for x in range(50)])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scripts.segmentation_consensus import PredictorVoting\n",
    "\n",
    "votes = PredictorVoting()\n",
    "n_votes, pred_vote = votes.voting(\n",
    "    nyu40_predictions=[cv2.resize(cmx, (1296, 968), interpolation=cv2.INTER_NEAREST)],\n",
    "    ade20k_predictions=[intern],\n",
    "    wn199_predictions=[ovseg_wn]\n",
    ")\n",
    "vis = VisImage(img)\n",
    "draw_sem_seg(pred_vote, vis, classes=[x['name'] for x in sorted(get_wordnet(), key=lambda x: x['id'])])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()\n",
    "vis = VisImage(img)\n",
    "draw_sem_seg(n_votes, vis, classes=[str(x) for x in range(10)])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from segmentation_tools.scannet_200_labels import CLASS_LABELS_200\n",
    "scannet_id_to_name = {x['id']: x['name'] for x in get_scannet_all()}\n",
    "names = []\n",
    "for x in range(1500):\n",
    "    if x in scannet_id_to_name:\n",
    "        names.append(scannet_id_to_name[x])\n",
    "    else:\n",
    "        names.append('unknown')\n",
    "mask3d = cv2.imread(f'{scene_dir}/pred_mask3d_rendered/{key}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "vis = VisImage(img)\n",
    "draw_sem_seg(mask3d, vis, classes=names, alpha=0.8)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consensus = cv2.imread(f'{scene_dir}/pred_consensus_5_scannet/{key}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "vis = VisImage(img)\n",
    "draw_sem_seg(consensus, vis, \n",
    "             classes=[x['name'] for x in sorted(get_wordnet(), key=lambda x: x['id'])],\n",
    "             colors=[x['color'] for x in sorted(get_wordnet(), key=lambda x: x['id'])])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consensus = cv2.imread(f'{scene_dir}/pred_consensus_noscannet/{key}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "vis = VisImage(img)\n",
    "draw_sem_seg(consensus, vis, \n",
    "             classes=[x['name'] for x in sorted(get_wordnet(), key=lambda x: x['id'])],\n",
    "             colors=[x['color'] for x in sorted(get_wordnet(), key=lambda x: x['id'])])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdfstudio = cv2.imread(f'{scene_dir}/pred_sdfstudio_2023-07-19_164624/{(key // 2):05d}.png',\n",
    "                   cv2.IMREAD_UNCHANGED)\n",
    "vis = VisImage(img)\n",
    "draw_sem_seg(sdfstudio, vis, \n",
    "             classes=[x['name'] for x in sorted(get_wordnet(), key=lambda x: x['id'])],\n",
    "             colors=[x['color'] for x in sorted(get_wordnet(), key=lambda x: x['id'])])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(vis.get_image())\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREFIX = '/home/weders/'\n",
    "\n",
    "scenes = [\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0000_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0458_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0164_02/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0518_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0474_01/',\n",
    "]\n",
    "\n",
    "# scannet voting weight 5 patchloss 0.01\n",
    "sdfstudio_paths = [\n",
    "                   'pred_sdfstudio_2023-07-28_195241/{k:05d}.png', #000\n",
    "                   'pred_sdfstudio_2023-07-28_154310/{k:05d}.png', #458\n",
    "                   'pred_sdfstudio_2023-07-28_154200/{k:05d}.png', #164\n",
    "                   'pred_sdfstudio_2023-07-28_154206/{k:05d}.png', #518\n",
    "                   'pred_sdfstudio_2023-07-28_154310/{k:05d}.png',#474\n",
    "                  ]\n",
    "\n",
    "# scannet voting weight 5\n",
    "sdfstudio_paths = [\n",
    "                   'pred_sdfstudio_2023-07-28_171544/{k:05d}.png', #000\n",
    "                   'pred_sdfstudio_2023-07-28_154244/{k:05d}.png', #458\n",
    "                   'pred_sdfstudio_2023-07-28_154207/{k:05d}.png', #164\n",
    "                   'pred_sdfstudio_2023-07-28_154200/{k:05d}.png', #518\n",
    "                   'pred_sdfstudio_2023-07-28_154249/{k:05d}.png',#474\n",
    "                  ]\n",
    "\n",
    "\n",
    "# labelmaker3d final\n",
    "sdfstudio_paths = [\n",
    "                   'pred_sdfstudio_2023-07-30_112430/{k:05d}.png', #000\n",
    "                   'pred_sdfstudio_2023-07-30_104953/{k:05d}.png', #458\n",
    "                   'pred_sdfstudio_2023-07-30_104700/{k:05d}.png', #164\n",
    "                   'pred_sdfstudio_2023-07-30_104735/{k:05d}.png', #518\n",
    "                   'pred_sdfstudio_2023-07-30_105014/{k:05d}.png',#474\n",
    "                  ]\n",
    "\n",
    "# semantic nerf predictions\n",
    "semantic_nerf_paths = [\n",
    "                   'pred_sdfstudio_2023-08-02_003056/{k:05d}.png', #000\n",
    "                   'pred_sdfstudio_2023-08-02_000600/{k:05d}.png', #458\n",
    "                   'pred_sdfstudio_2023-08-02_000339/{k:05d}.png', #164\n",
    "                   'pred_sdfstudio_2023-08-02_000401/{k:05d}.png', #518\n",
    "                   'pred_sdfstudio_2023-08-02_000611/{k:05d}.png',#474\n",
    "                  ]\n",
    "\n",
    "# semantic nerf predictions\n",
    "noscannet_paths = [\n",
    "                   'pred_sdfstudio_2023-08-02_015512/{k:05d}.png', #000\n",
    "                   'pred_sdfstudio_2023-08-02_002220/{k:05d}.png', #458\n",
    "                   'pred_sdfstudio_2023-08-02_002042/{k:05d}.png', #164\n",
    "                   'pred_sdfstudio_2023-08-02_083237/{k:05d}.png', #518\n",
    "                   'pred_sdfstudio_2023-08-02_083537/{k:05d}.png',#474\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scene = 'scene0458_00'\n",
    "scene_idx = -4\n",
    "\n",
    "scenes_ = [scenes[scene_idx]]\n",
    "overwrite_confmat = True\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='label-filt/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=['scannet'])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=2,\n",
    "                                pred_template=sdfstudio_paths[scene_idx],\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['labelmaker3d'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='pred_consensus_5_scannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['consensus'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='pred_consensus_noscannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['cons. w\\o sn'])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "for i, x in enumerate(matcher.right_ids):\n",
    "    if confmat.sum(0)[i+1] > 0:\n",
    "        columns.append(classid2wn[x])\n",
    "print(scene)\n",
    "df[columns].sort_values('mIoU', ascending=False).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scene = 'scene0000_00'\n",
    "scene_idx = -5\n",
    "\n",
    "scenes_ = [scenes[scene_idx]]\n",
    "overwrite_confmat = True\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='label-filt/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=['scannet'])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=2,\n",
    "                                pred_template=sdfstudio_paths[scene_idx],\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['labelmaker3d'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='pred_consensus_5_scannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['consensus'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='pred_consensus_noscannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['cons. w\\o sn'])])\n",
    "\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "for i, x in enumerate(matcher.right_ids):\n",
    "    if confmat.sum(0)[i+1] > 0:\n",
    "        columns.append(classid2wn[x])\n",
    "print(scene)\n",
    "df[columns].sort_values('mIoU', ascending=False).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scene0164_02\n",
    "\n",
    "scene = 'scene0164_02'\n",
    "scene_idx = -3\n",
    "\n",
    "scenes_ = [scenes[scene_idx]]\n",
    "overwrite_confmat = True\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='label-filt/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=['scannet'])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=2,\n",
    "                                pred_template=sdfstudio_paths[scene_idx],\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['labelmaker3d'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='pred_consensus_5_scannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['consensus'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='pred_consensus_noscannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['cons. w\\o sn'])])\n",
    "\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "for i, x in enumerate(matcher.right_ids):\n",
    "    if confmat.sum(0)[i+1] > 0:\n",
    "        columns.append(classid2wn[x])\n",
    "print(scene)\n",
    "df[columns].sort_values('mIoU', ascending=False).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scene = 'scene0518_00'\n",
    "scene_idx = -2\n",
    "\n",
    "scenes_ = [scenes[scene_idx]]\n",
    "overwrite_confmat = True\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='label-filt/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=['scannet'])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=2,\n",
    "                                pred_template=sdfstudio_paths[scene_idx],\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['labelmaker3d'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='pred_consensus_5_scannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['consensus'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='pred_consensus_noscannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['cons. w\\o sn'])])\n",
    "\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "for i, x in enumerate(matcher.right_ids):\n",
    "    if confmat.sum(0)[i+1] > 0:\n",
    "        columns.append(classid2wn[x])\n",
    "print(scene)\n",
    "df[columns].sort_values('mIoU', ascending=False).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scene = 'scene0474_01'\n",
    "scene_idx = -1\n",
    "\n",
    "scenes_ = [scenes[scene_idx]]\n",
    "overwrite_confmat = True\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=1,\n",
    "                                pred_template='label-filt/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=['scannet'])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=2,\n",
    "                                pred_template=sdfstudio_paths[scene_idx],\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['labelmaker3d'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_consensus_5_scannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['consensus'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes_,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_consensus_noscannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['cons. w\\o sn'])])\n",
    "\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "for i, x in enumerate(matcher.right_ids):\n",
    "    if confmat.sum(0)[i+1] > 0:\n",
    "        columns.append(classid2wn[x])\n",
    "print(scene)\n",
    "df[columns].sort_values('mIoU', ascending=False).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "overwrite_confmat = True\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "print('ScanNet')\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='label-filt/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                subsampling=1,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=['scannet']);\n",
    "\n",
    "print('LabelMaker')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=2,\n",
    "                                pred_template=sdfstudio_paths,\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['labelmaker3d'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_consensus_5_scannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['consensus'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_consensus_noscannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['cons. w\\o sn'])])\n",
    "\n",
    "print('Semantic NeRF')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=2,\n",
    "                                pred_template=semantic_nerf_paths,\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['SemanticNerf'])])\n",
    "\n",
    "print('NoScannet')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=2,\n",
    "                                pred_template=noscannet_paths,\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['No Scannet'])])\n",
    "\n",
    "display(df.T)\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "# for i, x in enumerate(matcher.right_ids):\n",
    "#     if confmat.sum(0)[i+1] > 0:\n",
    "#         columns.append(classid2wn[x])\n",
    "# df[columns].sort_values('mIoU', ascending=False).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d evaluation performance scannet\n",
    "\n",
    "scenes = [\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0000_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0458_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0164_02/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0518_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0474_01/',\n",
    "]\n",
    "\n",
    "overwrite_confmat = True\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "print('ovseg')\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template='pred_ovseg_wn_nodef/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                subsampling=1,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=['OVSeg']);\n",
    "\n",
    "print('Intern')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'ade20k',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_internimage/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['InternImage'])])\n",
    "\n",
    "\n",
    "print('CMX')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'nyu40id',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_cmx/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['CMX'])])\n",
    "\n",
    "print('mask3d')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_mask3d_rendered/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['Mask3D'])])\n",
    "\n",
    "\n",
    "display(df.T)\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "# for i, x in enumerate(matcher.right_ids):\n",
    "#     if confmat.sum(0)[i+1] > 0:\n",
    "#         columns.append(classid2wn[x])\n",
    "# df[columns].sort_values('mIoU', ascending=False).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d evaluation performance replica\n",
    "\n",
    "scenes = [\n",
    "          # f'{PATH_PREFIX}/scratch/scratch/scannetter/room_0_1/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/room_1_1/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/room_2_1/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/office_0_1/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/office_1_1/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/office_2_1/',\n",
    "          # f'{PATH_PREFIX}/scratch/scratch/scannetter/office_3_1/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/office_4_1/',\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "sdfstudio_paths = [\n",
    "                    'pred_sdfstudio_2023-08-03_210125/{k:05d}.png',\n",
    "                    'pred_sdfstudio_2023-08-03_210350/{k:05d}.png',\n",
    "                    'pred_sdfstudio_2023-08-03_201030/{k:05d}.png',\n",
    "                    'pred_sdfstudio_2023-08-03_201254/{k:05d}.png',\n",
    "                    'pred_sdfstudio_2023-08-03_201821/{k:05d}.png',\n",
    "                    'pred_sdfstudio_2023-08-03_204934/{k:05d}.png'\n",
    "                   \n",
    "]\n",
    "\n",
    "overwrite_confmat = True\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "print('ovseg')\n",
    "matcher = LabelMatcher('wn199', 'replicaid')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199',\n",
    "                                'replicaid',\n",
    "                                pred_template='pred_ovseg_wn_nodef/{k}.png',\n",
    "                                label_template='semantic_class/semantic_class_{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                subsampling=1,\n",
    "                                n_jobs=8)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=['OVSeg']);\n",
    "\n",
    "print('Intern')\n",
    "matcher = LabelMatcher('ade20k', 'replicaid')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'ade20k',\n",
    "                                'replicaid',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_internimage/{k}.png',\n",
    "                                label_template='semantic_class/semantic_class_{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['InternImage'])])\n",
    "\n",
    "\n",
    "print('CMX')\n",
    "matcher = LabelMatcher('nyu40id', 'replicaid')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'nyu40id',\n",
    "                                'replicaid',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_cmx/{k}.png',\n",
    "                                label_template='semantic_class/semantic_class_{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['CMX'])])\n",
    "\n",
    "print('mask3d')\n",
    "matcher = LabelMatcher('id', 'replicaid')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'id',\n",
    "                                'replicaid',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_mask3d_rendered/{k}.png',\n",
    "                                label_template='semantic_class/semantic_class_{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['Mask3D'])])\n",
    "\n",
    "print('consensus')\n",
    "matcher = LabelMatcher('wn199', 'replicaid')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199',\n",
    "                                'replicaid',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_wn_consensus/{k}.png',\n",
    "                                label_template='semantic_class/semantic_class_{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['Conensus'])])\n",
    "\n",
    "print('labelmaker3d')\n",
    "matcher = LabelMatcher('wn199', 'replicaid')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199',\n",
    "                                'replicaid',\n",
    "                                subsampling=1,\n",
    "                                pred_template=sdfstudio_paths,\n",
    "                                label_template='semantic_class/semantic_class_{k}.png',\n",
    "                                overwrite_confmat=True,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['Labelmaker3D'])])\n",
    "\n",
    "display(df.T)\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "# for i, x in enumerate(matcher.right_ids):\n",
    "#     if confmat.sum(0)[i+1] > 0:\n",
    "#         columns.append(classid2wn[x])\n",
    "# df[columns].sort_values('mIoU', ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consensus ablation\n",
    "\n",
    "scenes = [\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0000_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0458_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0164_02/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0518_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0474_01/',\n",
    "]\n",
    "\n",
    "overwrite_confmat = True\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "method = 'cmx'\n",
    "print(f'consensus w/o {method}')\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template=f'pred_consensus_no_{method}' + '/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                subsampling=1,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=[f'consensus w/o {method}']);\n",
    "\n",
    "method = 'intern'\n",
    "print(f'consensus w/o {method}')\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template=f'pred_consensus_no_{method}' + '/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                subsampling=1,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=[f'consensus w/o {method}'])])\n",
    "\n",
    "\n",
    "method = 'mask3d'\n",
    "print(f'consensus w/o {method}')\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template=f'pred_consensus_no_{method}' + '/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                subsampling=1,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=[f'consensus w/o {method}'])])\n",
    "\n",
    "method = 'ovseg'\n",
    "print(f'consensus w/o {method}')\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_template=f'pred_consensus_no_{method}' + '/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                subsampling=1,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=[f'consensus w/o {method}'])])\n",
    "\n",
    "metrics, confmat = segmentation_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                subsampling=1,\n",
    "                                pred_template='pred_consensus_noscannet/{k}.png',\n",
    "                                label_template='label_agile3d/{k}.png',\n",
    "                                overwrite_confmat=overwrite_confmat,\n",
    "                                n_jobs=8)\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['consensus w\\o scannet'])])\n",
    "\n",
    "\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "# for i, x in enumerate(matcher.right_ids):\n",
    "#     if confmat.sum(0)[i+1] > 0:\n",
    "#         columns.append(classid2wn[x])\n",
    "# df[columns].sort_values('mIoU', ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PATH_PREFIX = '/home/weders/'\n",
    "\n",
    "scenes = [f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0000_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0458_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0164_02/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0518_00/',\n",
    "          f'{PATH_PREFIX}/scratch/scratch/scannetter/scene0474_01/',\n",
    "]\n",
    "\n",
    "\n",
    "labels_3d_labelmaker = [p.split('/')[-2] + '_labels_3d.txt' for p in sdfstudio_paths]\n",
    "labels_3d_semantic_nerf = [p.split('/')[-2] + '_labels_3d.txt' for p in semantic_nerf_paths]\n",
    "labels_3d_noscannet = [p.split('/')[-2] + '_labels_3d.txt' for p in noscannet_paths]\n",
    "\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = pointcloud_eval.evaluate_scenes(scenes,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_dir='label-filt',\n",
    "                                pred_pointcloud='{s}_vh_clean.ply',\n",
    "                                pred_classes='label-filt_labels_3d.txt',\n",
    "                                label_pointcloud='{s}_vh_clean.ply',\n",
    "                                label_classes='label_agile3d_labels_3d.txt',\n",
    "                                overwrite_confmat=True,\n",
    "                                n_jobs=16)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.DataFrame(d, index=['scannet'])\n",
    "\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = pointcloud_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_dir='label-filt',\n",
    "                                pred_pointcloud='{s}_vh_clean.ply',\n",
    "                                pred_classes=labels_3d_labelmaker,\n",
    "                                label_pointcloud='{s}_vh_clean.ply',\n",
    "                                label_classes='label_agile3d_labels_3d.txt',\n",
    "                                overwrite_confmat=True,\n",
    "                                n_jobs=16)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['LabelMaker3D'])])\n",
    "\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = pointcloud_eval.evaluate_scenes(scenes,\n",
    "                                'id',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_dir='label-filt',\n",
    "                                pred_pointcloud='{s}_vh_clean.ply',\n",
    "                                pred_classes=labels_3d_semantic_nerf,\n",
    "                                label_pointcloud='{s}_vh_clean.ply',\n",
    "                                label_classes='label_agile3d_labels_3d.txt',\n",
    "                                overwrite_confmat=True,\n",
    "                                n_jobs=16)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['SemanticNerf'])])\n",
    "\n",
    "matcher = LabelMatcher('id', 'wn199-merged-v2')\n",
    "metrics, confmat = pointcloud_eval.evaluate_scenes(scenes,\n",
    "                                'wn199-merged-v2',\n",
    "                                'wn199-merged-v2',\n",
    "                                pred_dir='label-filt',\n",
    "                                pred_pointcloud='{s}_vh_clean.ply',\n",
    "                                pred_classes=labels_3d_noscannet,\n",
    "                                label_pointcloud='{s}_vh_clean.ply',\n",
    "                                label_classes='label_agile3d_labels_3d.txt',\n",
    "                                overwrite_confmat=True,\n",
    "                                n_jobs=16)\n",
    "\n",
    "d = {'tAcc': [metrics['tAcc']], 'mIoU': [metrics['mIoU']], 'mAcc': [metrics['mAcc']]}\n",
    "d.update({classid2wn[x]: [metrics['iou'][i]] for i, x in enumerate(matcher.right_ids)})\n",
    "df = pd.concat([df, pd.DataFrame(d, index=['LabelMaker3D w/o Scannet'])])\n",
    "\n",
    "\n",
    "columns = ['tAcc', 'mIoU', 'mAcc']\n",
    "for i, x in enumerate(matcher.right_ids):\n",
    "    if confmat.sum(0)[i+1] > 0:\n",
    "        columns.append(classid2wn[x])\n",
    "df[columns].sort_values('mIoU', ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scannetter",
   "language": "python",
   "name": "scannetter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
